<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="Fair NLP, non-stereotypical bias evaluation, gender bias, large language models, fairness, stereotypes">
    <title>Are Models Biased on Text Without Gender-related Language?</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <script src="https://d3js.org/d3.v4.js"></script>
    <!-- <script src="https://d3js.org/d3-scale-chromatic.v0.3.min.js"></script> -->
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
        <div class="content">
            <h1 class="title"><strong>Are Models Biased on Text without Gender-related Language?</strong></h1>
            <p id="authors">
                <span>
                    <a href="https://pastelbelem8.github.io/">Catarina G. Belem</a>
                    <a href="https://preethiseshadri518.github.io/">Preethi Seshadri</a>
                    <a href="https://yasamanrazeghi.com/">Yasaman Razeghi</a>
                    <a href="https://sameersingh.org/">Sameer Singh</a>
                </span>
                <br>
                <span class="affiliation">University of California Irvine</span>
            </p>
            <font size="+2">
                <p class="links">
                    <a href="https://openreview.net/forum?id=w1JanwReU6" target="_blank" class="btn btn-lg"><span class="icon"><i class="ai ai-arxiv"></i></span>&nbsp;Paper</a>
                    <a href="https://www.youtube.com/watch?v=gmqBoBSYj9U" target="_blank" class="btn btn-lg"><span class="icon"><i class="fa-solid fa-video"></i></span>&nbsp;Video</a>
                    <a href="https://github.com/ucinlp/unstereo-eval/tree/main/datasets" target="_blank" class="btn btn-lg"><span class="icon"><i class="fa-solid fa-database"></i></span>&nbsp;Dataset</a>
                    <a href="https://github.com/ucinlp/unstereo-eval" target="_blank" class="btn btn-lg"><span class="icon"><i class="fa-brands fa-github"></i></span>&nbsp;Code</a>
                </p>
            </font>
        </div>
        <div class="content">
            <h2 class="title">Abstract</h2>
            <p id="abstract">
                We introduce <strong>UnStereoEval (USE)</strong>, a novel framework tailored for investigating gender bias in stereotype-free scenarios. 
                USE defines a sentence-level score based on pretraining data statistics to determine if the sentence contain minimal word-gender associations. 
                To systematically benchmark the fairness of popular language models in stereotype-free scenarios, we utilize USE to automatically generate benchmarks without any gender-related language. 
                By leveraging USE's sentence-level score, we also repurpose prior gender bias benchmarks (Winobias and Winogender) for non-stereotypical evaluation. 
                Surprisingly, we find low fairness across <strong>all 28 evaluated models</strong>. 
                Concretely, models demonstrate fair behavior in <strong>only 9%-41% of stereotype-free sentences</strong>, suggesting that bias does not solely stem from the presence of gender-related words.
                These results raise important questions about where underlying model biases come from and highlight the need for more systematic and comprehensive bias evaluation. 
            </p>
        </div>

        <div class="content">
            <h2 class="title">Background</h2>
            <p> Gender bias research has been pivotal in revealing undesirable behaviors in large language models, exposing serious gender stereotypes associated with occupations, and emotions. 
                A key observation in prior work is that models reinforce stereotypes as a consequence of the gendered correlations that are present in the training data. 
                In this paper, we focus on bias where the effect from training data is unclear, and instead address the question: <em>Do language models still exhibit gender bias in non-stereotypical settings?</em>
            </p>
        </div>
        <div class="content">
            <h2 class="title">Contributions</h2>
            <p id="contributions">
                Our results reveal that, even after ensuring the evaluation set is composed of sentence pairs that are not gender-correlated according to the pretraining data, models still tend to be overconfident and assign higher probability mass to one gender over the other.
                Key contributions of this work include: 
            </p>
            <ul>
                <li>Approaches gender bias in NLP from a new perspective, challenging previously held observations with the intent of better understanding model behavior.</li>
                <li>UnStereoEval (USE): a novel framework to study gender bias in stereotype-free scenarios.</li>
                <li>Proposes an automated way of creating large-scale diverse English benchmark constituting fluent English sentences that are gender neutral and whose words have minimal gender correlations.</li>
                <li>Leverages ChatGPT to propose a new evaluation benchmark and releases two repurposed stereotype-free versions of WinoBias and Winogender.</li>
            </ul>

        </div>
        <div class="content">
            <h2 class="title">UnStereoEval</h2>  
            <p id="unstereo-eval">
            </p>
            <figure class="main-figure">
                <img src="./assets/images/figure.png" alt="UnStereoEval" style="width:100%">
            </figure>
        </div>
        <div class="content">
            <h2 class="title">Creation of non-stereotypical benchmarks</h2>  
            <p id="unstereo-eval">
            </p>

            <figure class="main-figure">
                <img src="./assets/images/figure2.png" alt="UnStereoEval" style="width:100%">
            </figure>

        </div>
        <div class="content">Results</div>
        <div class="content">Limitations</div>
        <div class="content" id="BibTex">
            <h2 class="title">BibTeX</h2>
            <div>
                <code id="bibtex-textarea" readonly="true">
                    @inproceedings{belem2024-unstereoeval,
                        <br>&nbsp;&nbsp;title={Are Models Biased on Text without Gender-related Language?}, 
                        <br>&nbsp;&nbsp;author={Catarina G Bel{\'e}m and Preethi Seshadri and Yasaman Razeghi and Sameer Singh},
                        <br>&nbsp;&nbsp;month={May},
                        <br>&nbsp;&nbsp;year={2024},
                        <br>&nbsp;&nbsp;booktitle={The Twelfth International Conference on Learning Representations},
                        <br>&nbsp;&nbsp;url={https://openreview.net/forum?id=w1JanwReU6}
                        <br>}
                </code>         
        </div>


    <footer class="container-fluid py-5 pb-3 text-muted text-small text-center"><small>Copyright Â© 2024</small></footer>        
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js" integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF" crossorigin="anonymous"></script>
    <script type="text/javascript" src = "https://raw.githubusercontent.com/ucinlp/unstereo-eval/main/docs/scripts/base-utils.js"></script>

</body>
</html>
