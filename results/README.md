# Full results description 

Each data file `.csv.gz` consists of the number of sentence pairs in the dataset * 28. The files can be read using `pd.read_csv`. 
Each row in the dataframe corresponds to a single sentence pair and their corresponding evaluation using a language model. 
Note that all the information corresponding to a single test sentence pair should be in the row. 


Here is the list of metadata available for each of the datasets:

- `orig_index`: original index in the results file. It is 
- `word`: corresponds to the seed word used to bootstrap the generation of non-stereotypical sentences. Examples are `adolescent`, `wizards`.
- `target_word`: corresponds to the group word used to generate a specific template. We prompt ChatGPT twice to ensure that no gender-specific artifacts are included in the dataset.
- `sentence`: the sentence generated by ChatGPT.
- `has_placeholder`: whether the sentence has the pronoun placeholders. This is a simplified way of knowing whether the sentence contains at least one of the pronoun forms he/his/him/himself or she/her/her/herself.
- `template`: the template with the placeholders instead of the gendered pronouns. The pronoun replacements are as follows `{pronoun} -> he/she`, `{pronoun1} -> his/her` and `{pronoun2} -> him/her`.
- `modifications`: When creating the minimally distant pairs from the male versions to the female versions, we use the direct mapping between pronouns whenever possible. However, in some cases the pronoun `her` cannot be disambiguated with a single rule and requires additional knowledge about the context. We use ChatGPT to revise the prompt. This field accounts for all the differences between the two sentences. 
- `likely_under`: dictionary stating whether the template is likely under the female completion and the male copletion. In the `no-maxpmi-constraint` version, the field should have the unique value of `{'male': 'likely', 'female': 'likely'}`. 
- `is_natural`: whether the sentence is natural sounding and makes sense under both gendered completions. It is equivalent to `modifications == {'male': 'likely', 'female': 'likely'}`
- has_word: whether the template contains the exact seed word that it was prompted with `\b{word}\b`. Different gendered words have significantly different co-occurrence values.
- `is_revised`: whether the sentence had to be revised during the generation process. That is, for sentences that did not contain the placeholders, or the pronouns we attempt to revise them up to 40 times.
- `M_num_tokens`: number of tokens of the male completion of the template.
- `M_logprob`: log probability assigned by model `model` to the male completion of the template.
- `M_template`: the male completion of the template.
- `F_num_tokens`: number of tokens of the female completion of the template.
- `F_logprob`: log probability assigned by model `model` to the male completion of the template.
- `F_template`: the male completion of the template.
- `FM_logprob`: the log odd ratio between the female and the male completion. That is, F_logprob - M_logprob.
- `model`: the model that scored this sentence pair.
- `dataset`: the name of the dataset. It will be one of `USE-5`, `USE-10`, `USE-20`, `Winobias`, `Winogender`.
- `is_deduped`: whether the model was trained in a deduplicated version of the PILE dataset. Only applicable to Pythia models.
- `is_intervention`: whether the model was trained in a deduplicated version and had a gender swap intervention at later stages of the PILE dataset. Only applicable to Pythia models.
- `orig_model_name`: original model name
- `model_size`: model size
- `model_family`: model family. That is whether it belongs to 
- `max_gender_pmi`: MaxPMI(s) of the sentence
- `template_words_pmi`: the PMI of the template words. These will not account for the stopwords, since we have no co-occurrence counts for the stopwords. Please consult [Razhegi et al 2022](https://aclanthology.org/2022.emnlp-demos.39/) for details on the computation of the counts.